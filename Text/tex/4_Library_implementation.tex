In the following chapter the \numdbname library is described. At first, global design decisions are explained. Then the most important classes are analyzed and the particular tricks and optimizations used in the implementation are described.

\section{Chosen Technologies}

The library is written in the C++ programming language. It has been chosen by the following criteria:
\begin{itemize}
\item C++ is a compiled language. Dynamic and managed languages have a huge runtime overhead, that significantly affects general application performance, while not providing any serious advantage (at least from the perspective of scientific applications).
\item Modern C++ compilers applies lots of advanced code optimizations, increasing the gap between compiled and dynamic languages even further.
\item C++ has an advanced template system that helps to write highly reusable and extendable code, while adding no overhead in runtime.
\end{itemize}
The library uses some language and standard library features that have been introduced in C++14 standard. Therefore, the compiler must be C++14 conformant.

The build process is managed by the \pathname{CMake} software, one of the most popular tool in this category. A great number of other projects also use \pathname{CMake} for managing the build process. It is trivially to embed a one \libname{CMake}-based project into another.

\pathname{CMake} uses \pathname{CMakeLists.txt} file, that contains the project definition, to generate a make file (other generators are also supported). Then, a program or a library can be built by invocating the GNU \pathname{make} utility.

\section{Project Structure Overview}


\subsection{Library}
The library itself is divided into:
\begin{itemize}
\item [\pathname{include/numdb}] folder containing header files
\item [\pathname{lib}] folder with source files (that can be compiled separately and merged with the user program during the linkage stage)
\item [\pathname{test}] folder containing unit tests
\item [\pathname{benchmark}] folder with the benchmark program, that has been used to perform performance evaluation (\cref{ch:bench})
\end{itemize}
Since the library heavily relies on templates, the majority of code is placed in the header files.


\subsection{External Libraries}
This library relies on several support libraries. They are distributed along with the sources (except \libname{Boost.Math}) in the \pathname{3rdparty} folder. Since all of them use \pathname{CMake} software for building process, they are compiled automatically with the main project.
\begin{itemize}[leftmargin=2cm]
\item [\libname{function\_traits}] extends C++ standard library metaprogramming capabilities by defining the type trait that can \emph{deduce argument types} of a provided functor object.
\item [\libname{murmurhash2functor}] library contains \classname{murmurhash2} hash function\cite{murmurhash} implementation and wraps it into the interface, similar to the \classname{std::hash}.

         The demand for the \classname{std::hash} replacement is dictated by the fact that the standard hash is not suitable for the hash table~-- \classname{std::hash} for an integer number is defined as the number itself (at least on some compilers\cite{std_hash}); under certain circumstances, this can lead to a high number of hash collisions.
\item [\libname{Google Benchmark}] framework is used as a benchmark starter. Its responsibility is to run functions that are to be benchmarked, measure their running time and other metrics, and encode the result into one of common data formats (e.g. \classname{JSON}).
\item [\libname{Google Test}] framework enables unit testing in the project. It provides some helper function and macros to simplify writing of unit tests as well as a common facility to run and evaluate tests.
\item [\libname{Boost.Math}] provides some statistical functions that are required by the benchmark program. This is the only library that is not bundled with the project and must be installed separately.
\end{itemize}
\libname{function\_traits} and \libname{murmurhash2functor} are required by the library itself. Other libraries are needed for testing/benchmarking only.

\section{Source Code Overview}
In the following section individual parts of the library are analyzed. The numerical database is called \emph{function cache} in this implementation because it has a cleaner meaning than the less known numerical database term.

\subsection{numdb.h}
This is the main entry point of the \numdbname library. Users need to include this file into their project to gain access to the data structures provided by the library.
\subsection{function\_cache.h}
\classname{FunctionCache} is the main class that realizes the numerical database concept. However, it does not determine how items are stored~-- it takes a container type as a template parameter and stores all items in the instance of the container provided.

This class defines helper function, that are common for all numerical databases, and type definitions, e.g. \classname{args\_tuple\_t}~-- a tuple that can store arguments of a function call. What is more, the item retrieval operation, as described in [========================], is implemented with actual calls to the lookup and insertion routines forwarded to the underlying container.

\classname{FunctionCache} is responsible for calling the provided user function in case the requested item was not found in the container. All invocations are timed with a system clock; then the duration is converted into an initial priority that is assigned to the item (initial priority generator is used).

\subsection{Initial\_priority\_generator.h}
This header file contains two classes, \classname{MinMaxPriorityGenerator} and \classname{RatioPriorityGenerator}, that compute the item initial priority basing on the duration of the current user function call and durations of previous calls.

\classname{MinMaxPriorityGenerator} calculates a priority as a linear interpolation between the minimum and the maximum values. \classname{RatioPriorityGenerator} calculates it as a proportion to the current average value. The latter scheme proved to be fairer and is used in the final implementation.

What is more, both schemes have an adaption mechanism~-- the average is divided by 2 every $N$ iterations, so that the latest input would have a bigger influence on the final result than data from previous periods. At the same time, the historic data is not discarded completely.

\subsection{fair\_lru.h and fair\_lru.cpp}
\classname{FairLRU} class implements an alternative eviction strategy~-- the item accessed the least recently among all items is always chosen for eviction. It is achieved by maintaining a doubly linked list of all nodes. When a node is inserted, it is placed in the tail (end) of the list. When a node is accessed, it is extracted from its current position, then inserted in the tail of the list. Therefore, the least recently used node appears in the head (start) of the list. All mentioned operations~-- insertion at the end, extraction (with a known pointer to a node), extraction from the head~-- have $\mathcal{O}(1)$ time complexity.

To embed \classname{FairLRU} in a container, an instance of \classname{FairLRU} should be added as a class member and container nodes should be derived from the \classname{FairLRU::Node} class (it contains data members that are required for a doubly linked list implementation). Then all basic operations, namely \findop, \insertop, and \removeop, should call corresponding methods on the \classname{FairLRU} instance.

\subsection{fair\_lfu.h and fair\_lfu.cpp}
\classname{FairLFU} external interface and usage scenario are similar to the ones in \classname{FairLRU}. However, it differs in the way it choses items for eviction (see \cref{sssec:lfu}).

Internally, the two-level linked list implementation is used, as described by Shah, Mitra, and Matani\cite{lfu}. This implementation has been chosen because it guarantees $\mathcal{O}(1)$ time complexity on all basic operations. Another well-known LFU implementation is based on a binary heap, but it achieves only $\mathcal{O}(\log N)$ time complexity.

The implementation used in the library differs from the original one. When a new item is inserted, the original implementation always assigns 1 to the node hit count. This yields a very ineffective behavior as the LFU tends to evict nodes that have just been added and preserves older ones, even those that have been accessed only twice.

The solution of this problem, presented in the library, is to calculate the initial hit counter value as a hit count of the least frequently accessed node (the one that is in the list head and may be evicted in the next step) incremented by one. This approach ensures that a new node is never inserted at the list head.

As a side effect, this adds the priority aging process (the approach is inverted~-- priority of new items is boosted instead of decreasing priority of older ones).

\subsection{weighted\_search\_tree.h}
Basing on \cite{park90} and \cite{park94}, the original weighted search tree has been reimplemented. Unlike the original implementation, the adjustable priority aging is also implemented~-- while traversing over the AVL tree (during item lookup), priorities of all visited nodes are decreased, and the binary heap is adjusted accordingly.

The improved WST priority scheme (as discussed in \cref{sssec:improved_wst}) is used for the node priority representation. Another optimization is the elimination of an AVL balance factor as a separate structure member (in this case it takes at least 1 byte). It is embedded into the priority component~-- 2 bits are used for storing the balance factor, and remaining 30 are used for the priority (8 bits for the base priority and 22 bits for the accumulated priority). It is achieved with the \emph{C++ bit field} feature.

\subsection{hash\_table/}

\pathname{hash_table} folder contains \classname{FixedHashtableBase}, \classname{FixedHashtableBinaryHeap}, and \classname{FixedHashtableFairLU} classes.

\classname{FixedHashtableBase} defines hash table implementation, that is common for all derived classes. However, there is no logic for choosing a node to be evicted~-- \classname{FixedHashtableBase} forwards the call to its derived class, where this operation is implemented.

Normally, this polimorhic behavior can be achieved with a virtual method call. However, virtual invocation brings additional overhead. Another drawback is that a virtual call can not be inlined by a compiler. Note, that we are dealing with the static polymorphism~-- all functions that can be called are known at compile time and are never changed in runtime, in contrast to the dynamic polymorphism.

To simulate the static polymorphism, \emph{Curiously Recurring Template Pattern} is often used\cite{crtp}. The base class (that needs to call a function which implementation is provided only in the derived class) takes its derived class as a template argument. When a polymorphic method needs to be called, base class object casts \classname{this} pointer to the derived class and then calls the desired function. Name lookup mechanism finds the implementation of the method in the derived class and performs a call to it (see \cref{lst:crtp}). It is a regular call, so a compiler can apply call inlining and other optimizations.

\begin{listing}[tbp]
\caption{Curiously Recurring Template Pattern}
\label{lst:crtp}
\begin{minted}{cpp}
template <typename DerivedClass>
struct Base {
    void callFoo() {
        static_cast<DerivedClass*>(this)->foo();
    }
};
struct Derived : public Base<Derived> {
    void foo() {
        std::cout << "Derived foo" << std::endl;
    }
};

int main() {
    Derived d;
    d.callFoo(); //prints "Derived foo"
    return 0;
}
\end{minted}
\end{listing}

Two other classes, \classname{FixedHashtableFairLu} and \classname{FixedHashtableBinaryHeap}, derive \classname{FixedHashtableBase} and supplies the base class with the implementation of the method, that searches for the least valuable item, that is to be evicted. To choose the node, \classname{FixedHashtableFairLu} uses \classname{FairLRU} or \classname{FairLFU} manager (actually, the manager is passed as a template parameter, so it is possible to extend the implementation with a custom manager). \classname{FixedHashtableBinaryHeap} maintains a binary heap for item priorities. In fact, it acts very similar to the weighted search tree, but with the hash table used in place of the AVL tree.

\subsection{splay\_tree/}
\pathname{splay_tree} folder contains different variations of a splay tree. Practically the complete tree implementation is in \classname{SplayTreeBase} class. Similarly to the hash table implementation, the code for determining the least valuable item is excluded from the base class. Again, the derived classes are responsible for implementing it.

This splay tree implementation does not rely on parent pointer in any way. Therefore, it could be excluded from the node declaration. This would decrease the memory overhead per node. However, for some item eviction policies (LRU and LFU), a pointer to the parent is an inevitable requirement (for other policies it is not). To support both types of policies, a wrapper over a parent pointer is introduced. The wrapper interface consists of get and set operations. Two implementations of the wrapper are provided~-- an actual implementation, that encapsulates a real pointer, and a mock one, that stores no value.

Derived classes tell \classname{SplayTreeBase} (through a trait class) which wrapper implementation they require and \classname{SplayTreeBase} embeds the chosen wrapper into the \classname{SplayTreeBase::Node} structure.

Even though the mock wrapper contains no data members, the size of an empty structure can not be zero in C++\cite{sizeof_empty}. Therefore, when the wrapper is embedded into a node, it takes at least one byte while not containing any valuable information. This unnecessary overhead is eliminated using the \emph{Empty Member Optimization}\cite{ebo}.


There are two derived classes, that are responsible for the item eviction policy:
 \begin{itemize}[leftmargin=2cm]
 \item [\classname{SplayTreeFairLu}] is similar to the \classname{HashTableFairLu} class~-- it reuses LRU and LFU node eviction policies
 \item [\classname{SplayTreeBottomNode}] realizes the Splay eviction policy, as described in \cref{sssec:spolicy}
\end{itemize}

\subsection{concurrent\_adapters/}

\subsection{cndc}
